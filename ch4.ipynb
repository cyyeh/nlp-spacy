{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Training a neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, you'll learn how to update spaCy's statistical models to customize them for your use case – for example, to predict a new entity type in online comments. You'll write your own training loop from scratch, and understand the basics of how training works, along with tips and tricks that can make your custom NLP projects more successful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and updating models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resources: [slides](slides/chapter4_01_training-updating-models.md)\n",
    "\n",
    "Welcome to the final chapter, which is about one of the most exciting aspects of modern NLP: training your own models!\n",
    "\n",
    "In this lesson, you'll learn about training and updating spaCy's neural network models and the data you need for it – focusing specifically on the named entity recognizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why updating the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Better results on your specific domain\n",
    "- Learn classification schemes specifically for your problem\n",
    "- Essential for text classification\n",
    "- Very useful for named entity recognition\n",
    "- Less critical for part-of-speech tagging and dependency parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How training works?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Initialize** the model weights randomly with `nlp.begin_training`\n",
    "2. **Predict** a few examples with the current weights by calling `nlp.update`\n",
    "3. **Compare** prediction with true labels\n",
    "4. **Calculate** how to change weights to improve predictions\n",
    "5. **Update** weights slightly\n",
    "6. Go back to 2.\n",
    "\n",
    "![training](slides/static/training.png)\n",
    "\n",
    "- **Training data**: Examples and their annotations.\n",
    "- **Text**: The input text the model should predict a label for.\n",
    "- **Label**: The label the model should predict.\n",
    "- **Gradient**: How to change the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Training the entity recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The entity recognizer tags words and phrases in context\n",
    "- Each token can only be part of one entity\n",
    "- Examples need to come with context\n",
    "\n",
    "```python\n",
    "(\"iPhone X is coming\", {'entities': [(0, 8, 'GADGET')]})\n",
    "```\n",
    "\n",
    "- Texts with no entities are also important\n",
    "\n",
    "```python\n",
    "(\"I need a new phone! Any tips?\", {'entities': []})\n",
    "```\n",
    "\n",
    "- Goal: teach the model to generalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Examples of what we want the model to predict in context\n",
    "- Update an existing model: a few hundred to a few thousand examples\n",
    "- Train a new category: a few thousand to a million examples\n",
    "    - spaCy's English models: 2 million words\n",
    "- Usually created manually by human annotators\n",
    "- Can be semi-automated – for example, using spaCy's `Matcher`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('How to preorder the iPhone X', {'entities': [(20, 28, 'GADGET'), (20, 26, 'GADGET')]})\n",
      "('iPhone X is coming', {'entities': [(0, 8, 'GADGET'), (0, 6, 'GADGET')]})\n",
      "('Should I pay $1,000 for the iPhone X?', {'entities': [(28, 36, 'GADGET'), (28, 34, 'GADGET')]})\n",
      "('The iPhone 8 reviews are here', {'entities': [(4, 10, 'GADGET'), (4, 12, 'GADGET')]})\n",
      "('Your iPhone goes up to 11 today', {'entities': [(5, 11, 'GADGET')]})\n",
      "('I need a new phone! Any tips?', {'entities': []})\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.lang.en import English\n",
    "\n",
    "with open(\"exercises/iphone.json\") as f:\n",
    "    TEXTS = json.loads(f.read())\n",
    "\n",
    "nlp = English()\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern1 = [{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}]\n",
    "pattern2 = [{\"LOWER\": \"iphone\"}, {\"IS_DIGIT\": True, \"OP\": \"?\"}]\n",
    "matcher.add(\"GADGET\", None, pattern1, pattern2)\n",
    "\n",
    "TRAINING_DATA = []\n",
    "\n",
    "# Create a Doc object for each text in TEXTS\n",
    "for doc in nlp.pipe(TEXTS):\n",
    "    # Match on the doc and create a list of matched spans\n",
    "    spans = [doc[start:end] for match_id, start, end in matcher(doc)]\n",
    "    # Get (start character, end character, label) tuples of matches\n",
    "    entities = [(span.start_char, span.end_char, \"GADGET\") for span in spans]\n",
    "    # Format the matches as a (doc.text, entities) tuple\n",
    "    training_example = (doc.text, {\"entities\": entities})\n",
    "    # Append the example to the training data\n",
    "    TRAINING_DATA.append(training_example)\n",
    "\n",
    "print(*TRAINING_DATA, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resources: [slides](slides/chapter4_02_training-loop.md)\n",
    "\n",
    "While some other libraries give you one method that takes care of training a model, spaCy gives you full control over the training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The steps of a training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Loop** for a number of times.\n",
    "2. **Shuffle** the training data.\n",
    "3. **Divide** the data into batches.\n",
    "4. **Update** the model for each batch.\n",
    "5. **Save** the updated model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap: How training works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![training](slides/static/training.png)\n",
    "\n",
    "- **Training data**: Examples and their annotations.\n",
    "- **Text**: The input text the model should predict a label for.\n",
    "- **Label**: The label the model should predict.\n",
    "- **Gradient**: How to change the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "\n",
    "TRAINING_DATA = [\n",
    "    ('How to preorder the iPhone X', {'entities': [(20, 28, 'GADGET')]})\n",
    "    # And many more examples...\n",
    "]\n",
    "\n",
    "# Loop for 10 iterations\n",
    "for i in range(10):\n",
    "    # Shuffle the training data\n",
    "    random.shuffle(TRAINING_DATA)\n",
    "    # Create batches and iterate over them\n",
    "    for batch in spacy.util.minibatch(TRAINING_DATA):\n",
    "        # Split the batch in texts and annotations\n",
    "        texts = [text for text, anootation in batch]\n",
    "        annotations = [annotation for text, annotation in batch]\n",
    "        # Update the model\n",
    "        nlp.update(texts, annotations)\n",
    "        \n",
    "# Save the model\n",
    "# nlp.to_disk(path_to_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating an existing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Improve the predictions on new data\n",
    "- Especially useful to improve existing categories, like `PERSON`\n",
    "- Also possible to add new categories\n",
    "- Be careful and make sure the model doesn't \"forget\" the old ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up a new pipeline from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "\n",
    "examples = [\n",
    "    # And many more examples...\n",
    "]\n",
    "\n",
    "# Start with the blank English model\n",
    "# The blank model doesn't have any pipeline components, only the language data and tokenization rules.\n",
    "nlp = spacy.blank('en')\n",
    "\n",
    "# Create blank entity recognizer and add it to the pipeline\n",
    "ner = nlp.create_pipe('ner')\n",
    "nlp.add_pipe(ner)\n",
    "\n",
    "# Add a new label\n",
    "ner.add_label('GADGET')\n",
    "\n",
    "# Start the training\n",
    "nlp.begin_training()\n",
    "\n",
    "# Train for 10 iterations\n",
    "for itn in range(10):\n",
    "    random.shuffle(examples)\n",
    "    # Divide examples into batches\n",
    "    for batch in spacy.util.minibatch(examples, size=2):\n",
    "        texts = [text for text, annotation in batch]\n",
    "        annotations = [annotation for text, annotation in batch]\n",
    "        # Update the model\n",
    "        nlp.update(texts, annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best practices for training spaCy models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resources: [slides](slides/chapter4_03_training-best-practices.md)\n",
    "\n",
    "When you start running your own experiments, you might find that a lot of things just don't work the way you want them to. And that's okay.\n",
    "\n",
    "Training models is an iterative process, and you have to try different things until you find out what works best.\n",
    "\n",
    "In this lesson, I'll be sharing some best practices and things to keep in mind when training your own models.\n",
    "\n",
    "Let's take a look at some of the problems you may come across."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Models can \"forget\" things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Existing model can overfit on new data\n",
    "    - e.g.: if you only update it with `WEBSITE`, it can \"unlearn\" what a `PERSON` is\n",
    "- Also known as \"catastrophic forgetting\" problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1: Mix in previously correct predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For example, if you're training `WEBSITE`, also include examples of `PERSON`\n",
    "- Run existing spaCy model over data and extract all other relevant entities\n",
    "\n",
    "**BAD:**\n",
    "\n",
    "```python\n",
    "TRAINING_DATA = [\n",
    "    ('Reddit is a website', {'entities': [(0, 6, 'WEBSITE')]})\n",
    "]\n",
    "```\n",
    "\n",
    "**GOOD:**\n",
    "\n",
    "```python\n",
    "TRAINING_DATA = [\n",
    "    ('Reddit is a website', {'entities': [(0, 6, 'WEBSITE')]}),\n",
    "    ('Obama is a person', {'entities': [(0, 5, 'PERSON')]})\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Models can't learn everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- spaCy's models make predictions based on local context\n",
    "- Model can struggle to learn if decision is difficult to make based on context\n",
    "- Label scheme needs to be consistent and not too specific\n",
    "    - For example: `CLOTHING` is better than `ADULT_CLOTHING` and `CHILDRENS_CLOTHING`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2: Plan your label scheme carefully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pick categories that are reflected in local context\n",
    "- More generic is better than too specific\n",
    "- Use rules to go from generic labels to specific categories\n",
    "\n",
    "**BAD:**\n",
    "\n",
    "```python\n",
    "LABELS = ['ADULT_SHOES', 'CHILDRENS_SHOES', 'BANDS_I_LIKE']\n",
    "```\n",
    "\n",
    "**GOOD:**\n",
    "\n",
    "```python\n",
    "LABELS = ['CLOTHING', 'BAND']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resources: [slides](slides/chapter4_04_wrapping-up.md)\n",
    "\n",
    "Congratulations – you've made it to the end of the course!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your new spaCy skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extract linguistic features: part-of-speech tags, dependencies, named entities\n",
    "- Work with pre-trained statistical models\n",
    "- Find words and phrases using `Matcher` and `PhraseMatcher` match rules\n",
    "- Best practices for working with data structures `Doc`, `Token`, `Span`, `Vocab`, `Lexeme`\n",
    "- Find semantic similarities using word vectors\n",
    "- Write custom pipeline components with extension attributes\n",
    "- Scale up your spaCy pipelines and make them fast\n",
    "- Create training data for spaCy' statistical models\n",
    "- Train and update spaCy's neural network models with new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More things to do with spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Training and updating](https://spacy.io/usage/training) other pipeline components\n",
    "    - Part-of-speech tagger\n",
    "    - Dependency parser\n",
    "    - Text classifier\n",
    "- [Customizing the tokenizer](https://spacy.io/usage/linguistic-features#tokenization)\n",
    "    - Adding rules and exceptions to split text differently\n",
    "- [Adding or improving support for other languages](https://spacy.io/usage/adding-languages)\n",
    "    - 45+ languages currently\n",
    "    - Lots of room for improvement and more languages\n",
    "    - Allows training models for other languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
